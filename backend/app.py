from apscheduler.schedulers.background import BackgroundScheduler
from flask import Flask, jsonify, request, make_response, g
from flask_cors import CORS
import os
import requests
from bs4 import BeautifulSoup
import sqlite3
import datetime
import time
import random
import re
import threading
from datetime import datetime, timedelta
import sys
import schedule
import pytz
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from functools import lru_cache
import logging.config
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
import json
import pickle
from collections import defaultdict
import numpy as np

# Redis import (optional)
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

# ===== è¨­å®šã‚¯ãƒ©ã‚¹ =====
class Config:
    DEBUG = os.environ.get('DEBUG', 'False').lower() == 'true'
    REDIS_URL = os.environ.get('REDIS_URL', 'redis://localhost:6379')
    API_RATE_LIMIT = os.environ.get('API_RATE_LIMIT', '100 per hour')
    CACHE_TIMEOUT = int(os.environ.get('CACHE_TIMEOUT', '300'))
    LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')
    DATABASE_URL = os.environ.get('DATABASE_URL', 'sqlite:///boatrace_data.db')
    MAX_WORKERS = int(os.environ.get('MAX_WORKERS', '5'))
    SCRAPING_DELAY = float(os.environ.get('SCRAPING_DELAY', '5.0'))  # 5ç§’é–“éš”
    VENUE_COUNT = 24
    ENABLE_RACE_RESULTS = os.environ.get('ENABLE_RACE_RESULTS', 'True').lower() == 'true'
    MOBILE_OPTIMIZATION = os.environ.get('MOBILE_OPTIMIZATION', 'True').lower() == 'true'
    MAX_SCRAPING_PER_DAY = int(os.environ.get('MAX_SCRAPING_PER_DAY', '50'))  # 1æ—¥æœ€å¤§50å›
    CACHE_ONLY_MODE = os.environ.get('CACHE_ONLY_MODE', 'False').lower() == 'true'

# ===== ãƒ­ã‚°è¨­å®š =====
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'detailed': {
            'format': '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
        },
        'simple': {
            'format': '%(levelname)s - %(message)s'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'simple',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'class': 'logging.FileHandler',
            'filename': 'boatrace_api.log',
            'level': 'DEBUG',
            'formatter': 'detailed',
            'mode': 'a'
        }
    },
    'loggers': {
        'boatrace': {
            'level': 'DEBUG',
            'handlers': ['console', 'file'],
            'propagate': False
        }
    },
    'root': {
        'level': 'INFO',
        'handlers': ['console']
    }
}

logging.config.dictConfig(LOGGING_CONFIG)
logger = logging.getLogger('boatrace')

# ===== ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ =====
request_count = 0
error_count = 0
start_time = datetime.now()
response_times = []
scraping_count_today = 0
last_scraping_reset = datetime.now().date()

# ===== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åˆ¶é™ç®¡ç† =====
def can_scrape():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œå¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
    global scraping_count_today, last_scraping_reset
    
    today = datetime.now().date()
    if today != last_scraping_reset:
        scraping_count_today = 0
        last_scraping_reset = today
    
    if Config.CACHE_ONLY_MODE:
        logger.warning("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ªãƒ³ãƒªãƒ¼ãƒ¢ãƒ¼ãƒ‰: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åœæ­¢ä¸­")
        return False
    
    if scraping_count_today >= Config.MAX_SCRAPING_PER_DAY:
        logger.warning(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åˆ¶é™åˆ°é”: {scraping_count_today}/{Config.MAX_SCRAPING_PER_DAY}")
        return False
    
    return True

def record_scraping():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œã‚’è¨˜éŒ²"""
    global scraping_count_today
    scraping_count_today += 1
    logger.info(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ: {scraping_count_today}/{Config.MAX_SCRAPING_PER_DAY}")

# ===== Redisãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š =====
redis_client = None
if REDIS_AVAILABLE:
    try:
        redis_client = redis.Redis(
            host=os.environ.get('REDIS_HOST', 'localhost'),
            port=int(os.environ.get('REDIS_PORT', '6379')),
            db=int(os.environ.get('REDIS_DB', '0')),
            decode_responses=True,
            socket_timeout=5
        )
        redis_client.ping()
        logger.info("Redisæ¥ç¶šæˆåŠŸ")
    except Exception as e:
        logger.warning(f"Redisæ¥ç¶šå¤±æ•—: {e}")
        redis_client = None

# ===== AIåˆæœŸåŒ– =====
print("ğŸ” sys.pathè¨­å®šå®Œäº†ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹...")

try:
    from boat_race_prediction_system import BoatRaceAI
    print("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–é–‹å§‹...")
    ai_model = BoatRaceAI()
    print("âœ… ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°AIãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
    AI_AVAILABLE = True
except Exception as e:
    print(f"âŒ AI model initialization failed: {e}")
    print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}")
    AI_AVAILABLE = False

print(f"ğŸ” AIåˆæœŸåŒ–å‡¦ç†å®Œäº†: AI_AVAILABLE = {AI_AVAILABLE}")

# ===== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹ =====
class DatabaseManager:
    def __init__(self, db_path="boatrace_data.db"):
        self.db_path = db_path
        self.initialize_all_tables()
    
    def initialize_all_tables(self):
        """ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆé‡è¦ï¼‰
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS race_schedule (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            race_date TEXT,
            venue_code TEXT,
            venue_name TEXT,
            race_number INTEGER,
            scheduled_time TEXT,
            status TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(race_date, venue_code, race_number)
        )
        ''')
        
        # å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS race_entries (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            race_id TEXT,
            venue_code TEXT,
            race_number INTEGER,
            race_date TEXT,
            racer_id TEXT,
            boat_number INTEGER,
            racer_name TEXT,
            racer_class TEXT,
            age INTEGER,
            weight TEXT,
            region TEXT,
            branch TEXT,
            motor_number INTEGER,
            boat_id INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(race_id, boat_number)
        )
        ''')
        
        # ç›´å‰æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS pre_race_info (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            race_id TEXT,
            venue_code TEXT,
            race_number INTEGER,
            race_date TEXT,
            weather TEXT,
            wind_direction TEXT,
            wind_speed REAL,
            wave_height INTEGER,
            temperature REAL,
            water_temperature REAL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(race_id)
        )
        ''')
        
        # å±•ç¤ºã‚¿ã‚¤ãƒ ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS exhibition_times (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            race_id TEXT,
            boat_number INTEGER,
            exhibition_time REAL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(race_id, boat_number)
        )
        ''')
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS scraping_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            scraping_date TEXT,
            url TEXT,
            status TEXT,
            response_time REAL,
            data_count INTEGER,
            error_message TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # ä¼šå ´ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS venue_cache (
            venue_code TEXT PRIMARY KEY,
            venue_name TEXT,
            is_active BOOLEAN,
            current_race INTEGER,
            remaining_races INTEGER,
            status TEXT,
            last_updated TIMESTAMP,
            data_source TEXT
        )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–å®Œäº†")
    
    def get_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—"""
        return sqlite3.connect(self.db_path)
    
    def save_race_schedule(self, schedule_data):
        """ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä¿å­˜"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            for race in schedule_data:
                cursor.execute('''
                INSERT OR REPLACE INTO race_schedule 
                (race_date, venue_code, venue_name, race_number, scheduled_time, status)
                VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    race['race_date'],
                    race['venue_code'],
                    race['venue_name'],
                    race['race_number'],
                    race['scheduled_time'],
                    race['status']
                ))
            
            conn.commit()
            logger.info(f"ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¿å­˜: {len(schedule_data)}ä»¶")
        except Exception as e:
            logger.error(f"ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            conn.close()
    
    def save_race_entries(self, entries_data):
        """å‡ºèµ°è¡¨ã‚’ä¿å­˜"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            for entry in entries_data:
                cursor.execute('''
                INSERT OR REPLACE INTO race_entries 
                (race_id, venue_code, race_number, race_date, racer_id, boat_number,
                 racer_name, racer_class, age, weight, region, branch, motor_number, boat_id)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    entry['race_id'],
                    entry['venue_code'],
                    entry['race_number'],
                    entry['race_date'],
                    entry['racer_id'],
                    entry['boat_number'],
                    entry['racer_name'],
                    entry['racer_class'],
                    entry['age'],
                    entry['weight'],
                    entry['region'],
                    entry['branch'],
                    entry['motor_number'],
                    entry['boat_id']
                ))
            
            conn.commit()
            logger.info(f"å‡ºèµ°è¡¨ä¿å­˜: {len(entries_data)}ä»¶")
        except Exception as e:
            logger.error(f"å‡ºèµ°è¡¨ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            conn.close()

# ===== æ­£å¼ç«¶è‰‡ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ =====
class OfficialBoatraceCollector:
    def __init__(self, db_manager):
        self.db_manager = db_manager
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Referer': 'https://boatrace.jp/',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Cache-Control': 'max-age=0'
        })
        
        # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # ä¼šå ´ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        self.venue_mapping = {
            "01": "æ¡ç”Ÿ", "02": "æˆ¸ç”°", "03": "æ±Ÿæˆ¸å·", "04": "å¹³å’Œå³¶", "05": "å¤šæ‘©å·",
            "06": "æµœåæ¹–", "07": "è’²éƒ¡", "08": "å¸¸æ»‘", "09": "æ´¥", "10": "ä¸‰å›½",
            "11": "ã³ã‚ã“", "12": "ä½ä¹‹æ±Ÿ", "13": "å°¼å´", "14": "é³´é–€", "15": "ä¸¸äº€",
            "16": "å…å³¶", "17": "å®®å³¶", "18": "å¾³å±±", "19": "ä¸‹é–¢", "20": "è‹¥æ¾",
            "21": "èŠ¦å±‹", "22": "ç¦å²¡", "23": "å”æ´¥", "24": "å¤§æ‘"
        }
    
    def get_daily_schedule(self, date_str=None):
        """æœ¬æ—¥ã®å…¨ä¼šå ´ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—"""
        if not can_scrape():
            return self.get_cached_schedule(date_str)
        
        if date_str is None:
            date_str = datetime.now().strftime("%Y%m%d")
        
        try:
            logger.info(f"=== æ—¥æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—é–‹å§‹: {date_str} ===")
            record_scraping()
            
            # ãƒœãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹å…¬å¼ã‚µã‚¤ãƒˆã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸
            url = "https://boatrace.jp/"
            start_time = time.time()
            
            response = self.session.get(url, timeout=30)
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                schedule_data = self.parse_daily_schedule(response.content, date_str)
                
                # ãƒ­ã‚°è¨˜éŒ²
                self.log_scraping(date_str, url, "success", response_time, len(schedule_data))
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                if schedule_data:
                    self.db_manager.save_race_schedule(schedule_data)
                
                logger.info(f"æ—¥æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—å®Œäº†: {len(schedule_data)}ä¼šå ´")
                return schedule_data
            else:
                self.log_scraping(date_str, url, "error", response_time, 0, f"HTTP {response.status_code}")
                logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—å¤±æ•—: {response.status_code}")
                return self.get_cached_schedule(date_str)
                
        except Exception as e:
            logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.log_scraping(date_str, url, "error", 0, 0, str(e))
            return self.get_cached_schedule(date_str)
        finally:
            time.sleep(Config.SCRAPING_DELAY)  # 5ç§’å¾…æ©Ÿ
    
    def parse_daily_schedule(self, html_content, date_str):
        """æ—¥æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è§£æ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            schedule_data = []
            
            # é–‹å‚¬ä¼šå ´æƒ…å ±ã‚’å–å¾—
            venue_elements = soup.find_all('a', href=re.compile(r'/owpc/pc/race/racelist'))
            
            for venue_element in venue_elements:
                try:
                    href = venue_element.get('href')
                    venue_match = re.search(r'jcd=(\d{2})', href)
                    
                    if venue_match:
                        venue_code = venue_match.group(1)
                        venue_name = self.venue_mapping.get(venue_code, f"ä¼šå ´{venue_code}")
                        
                        # å„ä¼šå ´ã®è©³ç´°ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
                        venue_races = self.get_venue_race_schedule(venue_code, date_str)
                        schedule_data.extend(venue_races)
                        
                        time.sleep(Config.SCRAPING_DELAY)  # ä¼šå ´é–“ã§å¾…æ©Ÿ
                        
                except Exception as e:
                    logger.warning(f"ä¼šå ´æƒ…å ±è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
                    continue
            
            return schedule_data
            
        except Exception as e:
            logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_venue_race_schedule(self, venue_code, date_str):
        """ä¼šå ´ã®ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è¡¨å–å¾—"""
        if not can_scrape():
            return []
        
        try:
            # ä¼šå ´ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ãƒšãƒ¼ã‚¸
            url = f"https://boatrace.jp/owpc/pc/race/racelist?jcd={venue_code}&hd={date_str}"
            logger.info(f"ä¼šå ´{venue_code}ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è¡¨å–å¾—: {url}")
            
            record_scraping()
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                return self.parse_venue_schedule(response.content, venue_code, date_str)
            else:
                logger.warning(f"ä¼šå ´{venue_code}ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è¡¨å–å¾—å¤±æ•—: {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"ä¼šå ´{venue_code}ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è¡¨å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
        finally:
            time.sleep(Config.SCRAPING_DELAY)
    
    def parse_venue_schedule(self, html_content, venue_code, date_str):
        """ä¼šå ´ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è¡¨è§£æ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            venue_name = self.venue_mapping.get(venue_code, f"ä¼šå ´{venue_code}")
            races = []
            
            # ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è¡¨ã‚’æ¢ã™ï¼ˆå®Ÿéš›ã®HTMLæ§‹é€ ã«å¿œã˜ã¦èª¿æ•´ï¼‰
            time_tables = soup.find_all('table', class_='is-w495')
            
            if time_tables:
                for table in time_tables:
                    rows = table.find_all('tr')
                    
                    for i, row in enumerate(rows[1:], 1):  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                        try:
                            cells = row.find_all('td')
                            if len(cells) >= 2:
                                # ç¬¬1ã‚»ãƒ«ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ç•ªå·ã€ç¬¬2ã‚»ãƒ«ã‹ã‚‰æ™‚åˆ»ã‚’å–å¾—
                                race_number_cell = cells[0].get_text().strip()
                                time_cell = cells[1].get_text().strip()
                                
                                # ãƒ¬ãƒ¼ã‚¹ç•ªå·æŠ½å‡º
                                race_match = re.search(r'(\d+)R', race_number_cell)
                                if race_match:
                                    race_number = int(race_match.group(1))
                                else:
                                    race_number = i
                                
                                # æ™‚åˆ»æŠ½å‡º
                                time_match = re.search(r'(\d{1,2}):(\d{2})', time_cell)
                                if time_match:
                                    scheduled_time = f"{time_match.group(1).zfill(2)}:{time_match.group(2)}"
                                    
                                    races.append({
                                        'race_date': date_str,
                                        'venue_code': venue_code,
                                        'venue_name': venue_name,
                                        'race_number': race_number,
                                        'scheduled_time': scheduled_time,
                                        'status': 'scheduled'
                                    })
                                    
                        except Exception as e:
                            logger.warning(f"ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
                            continue
            
            # æ™‚åˆ»è¡¨ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ™‚åˆ»ã‚’ä½¿ç”¨
            if not races:
                logger.warning(f"ä¼šå ´{venue_code}: æ™‚åˆ»è¡¨ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ™‚åˆ»ã‚’ä½¿ç”¨")
                for race_number in range(1, 13):  # 1R-12R
                    # ä¸€èˆ¬çš„ãªç«¶è‰‡ã®é–‹å§‹æ™‚åˆ»ï¼ˆ15:00é–‹å§‹ã€25åˆ†é–“éš”ï¼‰
                    start_hour = 15
                    start_minute = (race_number - 1) * 25
                    
                    total_minutes = start_hour * 60 + start_minute
                    hour = total_minutes // 60
                    minute = total_minutes % 60
                    
                    scheduled_time = f"{hour:02d}:{minute:02d}"
                    
                    races.append({
                        'race_date': date_str,
                        'venue_code': venue_code,
                        'venue_name': venue_name,
                        'race_number': race_number,
                        'scheduled_time': scheduled_time,
                        'status': 'scheduled'
                    })
            
            logger.info(f"ä¼šå ´{venue_code}({venue_name}): {len(races)}ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»å–å¾—")
            return races
            
        except Exception as e:
            logger.error(f"ä¼šå ´ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»è¡¨è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_race_entries(self, venue_code, race_number, date_str):
        """æ­£å¼å‡ºèµ°è¡¨å–å¾—"""
        if not can_scrape():
            return self.get_cached_race_entries(venue_code, race_number, date_str)
        
        try:
            # å‡ºèµ°è¡¨ãƒšãƒ¼ã‚¸URL
            url = f"https://boatrace.jp/owpc/pc/race/racelist?rno={race_number}&jcd={venue_code}&hd={date_str}"
            logger.info(f"å‡ºèµ°è¡¨å–å¾—: ä¼šå ´{venue_code} {race_number}R")
            
            record_scraping()
            start_time = time.time()
            response = self.session.get(url, timeout=30)
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                entries_data = self.parse_race_entries(response.content, venue_code, race_number, date_str)
                
                # ãƒ­ã‚°è¨˜éŒ²
                self.log_scraping(date_str, url, "success", response_time, len(entries_data) if entries_data else 0)
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                if entries_data:
                    self.db_manager.save_race_entries(entries_data)
                
                return {
                    "status": "success",
                    "racers": entries_data,
                    "found_count": len(entries_data) if entries_data else 0
                }
            else:
                self.log_scraping(date_str, url, "error", response_time, 0, f"HTTP {response.status_code}")
                return self.get_cached_race_entries(venue_code, race_number, date_str)
                
        except Exception as e:
            logger.error(f"å‡ºèµ°è¡¨å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.log_scraping(date_str, url, "error", 0, 0, str(e))
            return self.get_cached_race_entries(venue_code, race_number, date_str)
        finally:
            time.sleep(Config.SCRAPING_DELAY)
    
    def parse_race_entries(self, html_content, venue_code, race_number, date_str):
        """å‡ºèµ°è¡¨è§£æï¼ˆæ­£å¼ç‰ˆï¼‰"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # å®Ÿéš›ã®å‡ºèµ°è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
            race_table = soup.find('table', class_='is-w495')
            
            if not race_table:
                # åˆ¥ã®æ–¹æ³•ã§å‡ºèµ°è¡¨ã‚’æ¢ã™
                race_table = soup.find('div', class_='table1')
            
            entries = []
            
            if race_table:
                rows = race_table.find_all('tr')
                
                for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚¹ã‚­ãƒƒãƒ—
                    try:
                        cells = row.find_all(['td', 'th'])
                        
                        if len(cells) >= 6:
                            # ã‚»ãƒ«ã‹ã‚‰æƒ…å ±æŠ½å‡º
                            boat_number = self.extract_boat_number(cells[0])
                            racer_info = self.extract_racer_info(cells[1])
                            
                            if boat_number and racer_info:
                                race_id = f"{date_str}{venue_code}{race_number:02d}"
                                
                                entry = {
                                    'race_id': race_id,
                                    'venue_code': venue_code,
                                    'race_number': race_number,
                                    'race_date': date_str,
                                    'boat_number': boat_number,
                                    'racer_id': racer_info.get('registration_number', ''),
                                    'racer_name': racer_info.get('name', ''),
                                    'racer_class': racer_info.get('class', ''),
                                    'age': racer_info.get('age', 0),
                                    'weight': racer_info.get('weight', ''),
                                    'region': racer_info.get('region', ''),
                                    'branch': racer_info.get('branch', ''),
                                    'motor_number': self.extract_motor_number(cells),
                                    'boat_id': self.extract_boat_id(cells)
                                }
                                entries.append(entry)
                                
                    except Exception as e:
                        logger.warning(f"å‡ºèµ°è¡¨è¡Œè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
                        continue
            
            logger.info(f"å‡ºèµ°è¡¨è§£æå®Œäº†: {len(entries)}å")
            return entries
            
        except Exception as e:
            logger.error(f"å‡ºèµ°è¡¨è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def extract_boat_number(self, cell):
        """è‰‡ç•ªæŠ½å‡º"""
        try:
            text = cell.get_text().strip()
            match = re.search(r'(\d+)', text)
            return int(match.group(1)) if match else None
        except:
            return None
    
    def extract_racer_info(self, cell):
        """é¸æ‰‹æƒ…å ±æŠ½å‡º"""
        try:
            text = cell.get_text().strip()
            
            # ç™»éŒ²ç•ªå·/ç´šåˆ¥ é¸æ‰‹å æ”¯éƒ¨/å¹´é½¢ãƒ»ä½“é‡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
            pattern = r'(\d{4})\s*/\s*([AB][12])\s*([^\n]+?)\s+([^/\n]+)/([^\n]+?)\s+(\d+)æ­³/(\d+\.\d+)kg'
            match = re.search(pattern, text, re.MULTILINE | re.DOTALL)
            
            if match:
                name_clean = re.sub(r'\s+', ' ', match.group(3)).strip()
                
                return {
                    'registration_number': match.group(1),
                    'class': match.group(2),
                    'name': name_clean,
                    'region': match.group(4).strip(),
                    'branch': match.group(5).strip(),
                    'age': int(match.group(6)),
                    'weight': f"{match.group(7)}kg"
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"é¸æ‰‹æƒ…å ±æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def extract_motor_number(self, cells):
        """ãƒ¢ãƒ¼ã‚¿ãƒ¼ç•ªå·æŠ½å‡º"""
        try:
            for cell in cells:
                text = cell.get_text().strip()
                motor_match = re.search(r'M(\d+)', text)
                if motor_match:
                    return int(motor_match.group(1))
            return random.randint(1, 100)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        except:
            return random.randint(1, 100)
    
    def extract_boat_id(self, cells):
        """ãƒœãƒ¼ãƒˆç•ªå·æŠ½å‡º"""
        try:
            for cell in cells:
                text = cell.get_text().strip()
                boat_match = re.search(r'B(\d+)', text)
                if boat_match:
                    return int(boat_match.group(1))
            return random.randint(1, 100)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        except:
            return random.randint(1, 100)
    
    def get_cached_schedule(self, date_str):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—"""
        try:
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
            SELECT venue_code, venue_name, race_number, scheduled_time, status
            FROM race_schedule
            WHERE race_date = ?
            ORDER BY venue_code, race_number
            ''', (date_str,))
            
            results = cursor.fetchall()
            conn.close()
            
            schedule_data = []
            for result in results:
                schedule_data.append({
                    'race_date': date_str,
                    'venue_code': result[0],
                    'venue_name': result[1],
                    'race_number': result[2],
                    'scheduled_time': result[3],
                    'status': result[4]
                })
            
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—: {len(schedule_data)}ä»¶")
            return schedule_data
            
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_cached_race_entries(self, venue_code, race_number, date_str):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‡ºèµ°è¡¨å–å¾—"""
        try:
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
            SELECT boat_number, racer_id, racer_name, racer_class, age, weight, region, branch
            FROM race_entries
            WHERE venue_code = ? AND race_number = ? AND race_date = ?
            ORDER BY boat_number
            ''', (venue_code, race_number, date_str))
            
            results = cursor.fetchall()
            conn.close()
            
            if results:
                entries = []
                for result in results:
                    entries.append({
                        'boat_number': result[0],
                        'registration_number': result[1],
                        'name': result[2],
                        'class': result[3],
                        'age': result[4],
                        'weight': result[5],
                        'region': result[6],
                        'branch': result[7]
                    })
                
                logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‡ºèµ°è¡¨å–å¾—: {len(entries)}å")
                return {
                    "status": "success",
                    "racers": entries,
                    "found_count": len(entries)
                }
            
            return {"status": "error", "message": "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
            
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‡ºèµ°è¡¨å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {"status": "error", "message": str(e)}
    
    def log_scraping(self, date_str, url, status, response_time, data_count, error_message=None):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚°è¨˜éŒ²"""
        try:
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
            INSERT INTO scraping_log 
            (scraping_date, url, status, response_time, data_count, error_message)
            VALUES (?, ?, ?, ?, ?, ?)
            ''', (date_str, url, status, response_time, data_count, error_message))
            
            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

# ===== ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹ =====
class RaceScheduleManager:
    def __init__(self, db_manager, data_collector):
        self.db_manager = db_manager
        self.data_collector = data_collector
        self.scheduler = None
        self.race_schedules = {}
        self.dynamic_jobs = {}
    
    def start_scheduled_tasks(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¿ã‚¹ã‚¯é–‹å§‹"""
        from apscheduler.schedulers.background import BackgroundScheduler
        
        self.scheduler = BackgroundScheduler()
        
        # æ¯æ—¥æœ6æ™‚: å‡ºèµ°è¡¨ä¸€æ‹¬å–å¾—
        self.scheduler.add_job(
            func=self.daily_data_collection,
            trigger="cron",
            hour=6,
            minute=0,
            id="daily_collection"
        )
        
        # 1æ™‚é–“ã”ã¨: ç›´å‰æƒ…å ±æ›´æ–°ãƒã‚§ãƒƒã‚¯
        self.scheduler.add_job(
            func=self.check_pre_race_updates,
            trigger="interval",
            hours=1,
            id="pre_race_check"
        )
        
        self.scheduler.start()
        logger.info("ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹")
    
    def daily_data_collection(self):
        """æœ6æ™‚å®Ÿè¡Œ: æœ¬æ—¥ã®å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        logger.info("=== æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ ===")
        
        try:
            today = datetime.now().strftime("%Y%m%d")
            
            # 1. å…¨ä¼šå ´ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—
            schedule_data = self.data_collector.get_daily_schedule(today)
            
            if schedule_data:
                # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†…éƒ¨ä¿å­˜
                self.race_schedules[today] = {}
                
                for race in schedule_data:
                    venue_code = race['venue_code']
                    
                    if venue_code not in self.race_schedules[today]:
                        self.race_schedules[today][venue_code] = []
                    
                    self.race_schedules[today][venue_code].append(race)
                
                # 2. å„ãƒ¬ãƒ¼ã‚¹ã®ç›´å‰æƒ…å ±å–å¾—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¨ˆç®—
                self.schedule_pre_race_updates(today)
                
                logger.info(f"æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {len(schedule_data)}ãƒ¬ãƒ¼ã‚¹")
            else:
                logger.warning("æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ãªã—")
                
        except Exception as e:
            logger.error(f"æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def schedule_pre_race_updates(self, date_str):
        """ç›´å‰æƒ…å ±æ›´æ–°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°"""
        try:
            if date_str not in self.race_schedules:
                return
            
            for venue_code, races in self.race_schedules[date_str].items():
                for race in races:
                    try:
                        # ãƒ¬ãƒ¼ã‚¹é–‹å§‹æ™‚åˆ»ã‹ã‚‰1æ™‚é–“å‰ã‚’è¨ˆç®—
                        race_time_str = f"{date_str} {race['scheduled_time']}"
                        race_time = datetime.strptime(race_time_str, "%Y%m%d %H:%M")
                        update_time = race_time - timedelta(hours=1)
                        
                        # ç¾åœ¨æ™‚åˆ»ã‚ˆã‚Šæœªæ¥ã®å ´åˆã®ã¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
                        if update_time > datetime.now():
                            job_id = f"pre_race_{venue_code}_{race['race_number']}_{date_str}"
                            
                            self.scheduler.add_job(
                                func=self.update_pre_race_info,
                                trigger="date",
                                run_date=update_time,
                                args=[venue_code, race['race_number'], date_str],
                                id=job_id
                            )
                            
                            logger.info(f"ç›´å‰æƒ…å ±æ›´æ–°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«: {job_id} at {update_time}")
                            
                    except Exception as e:
                        logger.warning(f"ç›´å‰æƒ…å ±ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        continue
                        
        except Exception as e:
            logger.error(f"ç›´å‰æƒ…å ±ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def update_pre_race_info(self, venue_code, race_number, date_str):
        """ç›´å‰æƒ…å ±æ›´æ–°ï¼ˆãƒ¬ãƒ¼ã‚¹é–‹å§‹1æ™‚é–“å‰å®Ÿè¡Œï¼‰"""
        logger.info(f"ç›´å‰æƒ…å ±æ›´æ–°: ä¼šå ´{venue_code} {race_number}R")
        
        try:
            # å±•ç¤ºã‚¿ã‚¤ãƒ ãƒ»æ°—è±¡æƒ…å ±ãªã©ã‚’å–å¾—
            # å®Ÿéš›ã«ã¯è¿½åŠ ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒå¿…è¦
            pass
            
        except Exception as e:
            logger.error(f"ç›´å‰æƒ…å ±æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def check_pre_race_updates(self):
        """1æ™‚é–“ã”ã¨å®Ÿè¡Œ: ç›´å‰æƒ…å ±æ›´æ–°ãŒå¿…è¦ãªãƒ¬ãƒ¼ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯"""
        logger.info("ç›´å‰æƒ…å ±æ›´æ–°ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ")
        
        try:
            current_time = datetime.now()
            today = current_time.strftime("%Y%m%d")
            
            # æœ¬æ—¥ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
            if today in self.race_schedules:
                for venue_code, races in self.race_schedules[today].items():
                    for race in races:
                        try:
                            race_time_str = f"{today} {race['scheduled_time']}"
                            race_time = datetime.strptime(race_time_str, "%Y%m%d %H:%M")
                            
                            # ãƒ¬ãƒ¼ã‚¹é–‹å§‹1-2æ™‚é–“å‰ãªã‚‰ç›´å‰æƒ…å ±æ›´æ–°
                            time_diff = (race_time - current_time).total_seconds() / 3600
                            
                            if 1 <= time_diff <= 2:
                                logger.info(f"ç›´å‰æƒ…å ±æ›´æ–°å¯¾è±¡: ä¼šå ´{venue_code} {race['race_number']}R")
                                # å®Ÿéš›ã®æ›´æ–°å‡¦ç†ã¯ã“ã“ã§å®Ÿè¡Œ
                                
                        except Exception as e:
                            logger.warning(f"ãƒ¬ãƒ¼ã‚¹æ™‚åˆ»ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
                            continue
                            
        except Exception as e:
            logger.error(f"ç›´å‰æƒ…å ±ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")

# ===== ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ =====
db_manager = DatabaseManager()
data_collector = OfficialBoatraceCollector(db_manager)
schedule_manager = RaceScheduleManager(db_manager, data_collector)

# ===== Flask ã‚¢ãƒ—ãƒªåˆæœŸåŒ– =====
app = Flask(__name__)
CORS(app)

# è¨­å®šé©ç”¨
app.config.from_object(Config)

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®š
limiter = Limiter(
    app,
    key_func=get_remote_address,
    default_limits=["1000 per hour", "50 per minute"]
)

# ===== ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¨™æº–åŒ–é–¢æ•° =====
def create_response(data=None, error=None, status_code=200, message=None):
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¨™æº–åŒ–"""
    response = {
        "timestamp": datetime.now().isoformat(),
        "status_code": status_code,
        "success": error is None,
        "scraping_status": {
            "count_today": scraping_count_today,
            "limit": Config.MAX_SCRAPING_PER_DAY,
            "cache_only_mode": Config.CACHE_ONLY_MODE
        }
    }
    
    if data is not None:
        response["data"] = data
    if error is not None:
        response["error"] = error
    if message is not None:
        response["message"] = message
        
    return jsonify(response), status_code

# ===== ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ãƒ•ãƒƒã‚¯ =====
@app.before_request
def before_request():
    global request_count
    request_count += 1
    g.start_time = time.time()
    
    # ãƒ¢ãƒã‚¤ãƒ«åˆ¤å®š
    user_agent = request.headers.get('User-Agent', '').lower()
    g.is_mobile = any(device in user_agent for device in ['mobile', 'android', 'iphone', 'ipad'])
    
    logger.info(f"Request: {request.method} {request.path}", extra={
        "method": request.method,
        "path": request.path,
        "user_agent": request.user_agent.string,
        "remote_addr": request.remote_addr,
        "is_mobile": g.is_mobile
    })

@app.after_request
def after_request(response):
    global response_times
    
    duration = time.time() - g.start_time
    response_times.append(duration)
    
    # æœ€æ–°100ä»¶ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®ã¿ä¿æŒ
    if len(response_times) > 100:
        response_times = response_times[-100:]
    
    logger.info(f"Response: {response.status_code} - {duration:.3f}s")
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'DENY'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    
    # ãƒ¢ãƒã‚¤ãƒ«æœ€é©åŒ–ãƒ˜ãƒƒãƒ€ãƒ¼
    if hasattr(g, 'is_mobile') and g.is_mobile:
        response.headers['Cache-Control'] = 'public, max-age=300'  # 5åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    
    return response

# ===== ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ =====
@app.errorhandler(404)
def not_found_error(error):
    global error_count
    error_count += 1
    
    logger.warning(f"404 Error: {request.path}")
    
    return create_response(
        error="ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
        status_code=404,
        message=f"ãƒ‘ã‚¹ '{request.path}' ã¯å­˜åœ¨ã—ã¾ã›ã‚“"
    )

@app.errorhandler(500)
def internal_error(error):
    global error_count
    error_count += 1
    
    logger.error(f"500 Error: {str(error)}")
    
    return create_response(
        error="å†…éƒ¨ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼",
        status_code=500,
        message="ã‚µãƒ¼ãƒãƒ¼ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    )

@app.errorhandler(429)
def ratelimit_error(error):
    logger.warning(f"Rate limit exceeded: {request.remote_addr}")
    
    return create_response(
        error="ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ",
        status_code=429,
        message="ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤šã™ãã¾ã™ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„"
    )

# ===== åŸºæœ¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ =====
@app.route('/')
def index():
    return jsonify({
        "service": "WAVE PREDICTOR - æ­£å¼ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾å¿œç‰ˆ",
        "version": "3.0.0",
        "status": "running",
        "ai_available": AI_AVAILABLE,
        "scraping_status": {
            "daily_count": scraping_count_today,
            "daily_limit": Config.MAX_SCRAPING_PER_DAY,
            "cache_only_mode": Config.CACHE_ONLY_MODE,
            "remaining": max(0, Config.MAX_SCRAPING_PER_DAY - scraping_count_today)
        },
        "features": [
            "æ­£å¼ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾å¿œ", 
            "é©æ­£ã‚¢ã‚¯ã‚»ã‚¹é »åº¦", 
            "å®Ÿéš›ã®ãƒ¬ãƒ¼ã‚¹æ™‚é–“å–å¾—",
            "å‹•çš„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°",
            "ã‚­ãƒ£ãƒƒã‚·ãƒ¥å„ªå…ˆã‚·ã‚¹ãƒ†ãƒ ",
            "AIäºˆæƒ³", 
            "ãƒ¢ãƒã‚¤ãƒ«æœ€é©åŒ–"
        ],
        "endpoints": {
            "daily_schedule": "/api/daily-schedule",
            "race_entries": "/api/race-entries/{venue_code}/{race_number}",
            "system_status": "/api/system-status",
            "scraping_status": "/api/scraping-status"
        }
    })

@app.route('/api/test', methods=['GET'])
@limiter.limit("100 per minute")
def test():
    return create_response(
        data={
            "message": "æ­£å¼ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç‰ˆAPIå‹•ä½œä¸­!", 
            "mobile_optimized": hasattr(g, 'is_mobile') and g.is_mobile,
            "scraping_count": scraping_count_today,
            "can_scrape": can_scrape()
        },
        message="APIæ­£å¸¸å‹•ä½œä¸­ï¼ˆé©æ­£ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç‰ˆï¼‰"
    )

# ===== æ­£å¼ãƒ‡ãƒ¼ã‚¿å–å¾—API =====
@app.route('/api/daily-schedule', methods=['GET'])
@limiter.limit("30 per minute")
def get_daily_schedule():
    """æœ¬æ—¥ã®å…¨ä¼šå ´ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—"""
    try:
        date_str = request.args.get('date', datetime.now().strftime("%Y%m%d"))
        
        logger.info(f"æ—¥æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {date_str}")
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
        schedule_data = data_collector.get_daily_schedule(date_str)
        
        if schedule_data:
            # ä¼šå ´åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            venues = {}
            for race in schedule_data:
                venue_code = race['venue_code']
                if venue_code not in venues:
                    venues[venue_code] = {
                        'venue_code': venue_code,
                        'venue_name': race['venue_name'],
                        'is_active': True,
                        'races': []
                    }
                venues[venue_code]['races'].append({
                    'race_number': race['race_number'],
                    'scheduled_time': race['scheduled_time'],
                    'status': race['status']
                })
            
            return create_response(
                data={
                    "date": date_str,
                    "venues": venues,
                    "total_venues": len(venues),
                    "total_races": len(schedule_data)
                },
                message="æ­£å¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†"
            )
        else:
            return create_response(
                error="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ",
                status_code=404,
                message="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚‚ã‚ã‚Šã¾ã›ã‚“"
            )
            
    except Exception as e:
        logger.error(f"æ—¥æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return create_response(error=str(e), status_code=500)

@app.route('/api/race-entries/<venue_code>/<int:race_number>', methods=['GET'])
@limiter.limit("20 per minute")
def get_race_entries_api(venue_code, race_number):
    """æ­£å¼å‡ºèµ°è¡¨å–å¾—API"""
    try:
        date_str = request.args.get('date', datetime.now().strftime("%Y%m%d"))
        
        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if venue_code not in [f"{i:02d}" for i in range(1, 25)]:
            return create_response(
                error="ç„¡åŠ¹ãªä¼šå ´ã‚³ãƒ¼ãƒ‰ã§ã™",
                status_code=400,
                message="ä¼šå ´ã‚³ãƒ¼ãƒ‰ã¯01-24ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„"
            )
            
        if not (1 <= race_number <= 12):
            return create_response(
                error="ç„¡åŠ¹ãªãƒ¬ãƒ¼ã‚¹ç•ªå·ã§ã™",
                status_code=400,
                message="ãƒ¬ãƒ¼ã‚¹ç•ªå·ã¯1-12ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„"
            )
        
        logger.info(f"æ­£å¼å‡ºèµ°è¡¨å–å¾—: ä¼šå ´{venue_code} {race_number}R {date_str}")
        
        # å‡ºèµ°è¡¨å–å¾—
        entries_result = data_collector.get_race_entries(venue_code, race_number, date_str)
        
        if entries_result and entries_result.get("status") == "success":
            venue_name = data_collector.venue_mapping.get(venue_code, f"ä¼šå ´{venue_code}")
            
            response_data = {
                "venue_code": venue_code,
                "venue_name": venue_name,
                "race_number": race_number,
                "race_date": date_str,
                "racer_extraction": entries_result,
                "data_source": "official_scraping" if can_scrape() else "cache",
                "mobile_optimized": hasattr(g, 'is_mobile') and g.is_mobile
            }
            
            return create_response(
                data=response_data,
                message="æ­£å¼å‡ºèµ°è¡¨å–å¾—å®Œäº†"
            )
        else:
            return create_response(
                error="å‡ºèµ°è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—",
                status_code=404,
                message="ãƒ¬ãƒ¼ã‚¹é–‹å‚¬çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
            )
            
    except Exception as e:
        logger.error(f"æ­£å¼å‡ºèµ°è¡¨API ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return create_response(error=str(e), status_code=500)

@app.route('/api/system-status', methods=['GET'])
@limiter.limit("60 per minute")
def get_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªAPI"""
    try:
        uptime = (datetime.now() - start_time).total_seconds()
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        # æœ¬æ—¥ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚°å–å¾—
        today = datetime.now().strftime("%Y%m%d")
        conn = db_manager.get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT COUNT(*), SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END)
        FROM scraping_log
        WHERE scraping_date = ?
        ''', (today,))
        
        log_result = cursor.fetchone()
        total_scraping = log_result[0] if log_result[0] else 0
        success_scraping = log_result[1] if log_result[1] else 0
        
        conn.close()
        
        system_data = {
            "system_status": "running",
            "version": "3.0.0",
            "ai_available": AI_AVAILABLE,
            "uptime": {
                "seconds": uptime,
                "formatted": str(timedelta(seconds=int(uptime)))
            },
            "scraping_status": {
                "daily_count": scraping_count_today,
                "daily_limit": Config.MAX_SCRAPING_PER_DAY,
                "success_rate": success_scraping / total_scraping if total_scraping > 0 else 0,
                "cache_only_mode": Config.CACHE_ONLY_MODE,
                "can_scrape": can_scrape(),
                "delay_seconds": Config.SCRAPING_DELAY
            },
            "performance": {
                "total_requests": request_count,
                "error_count": error_count,
                "avg_response_time": round(avg_response_time, 3),
                "success_rate": (request_count - error_count) / request_count if request_count > 0 else 0
            },
            "features": {
                "official_scraping": True,
                "dynamic_scheduling": True,
                "race_results_enabled": Config.ENABLE_RACE_RESULTS,
                "mobile_optimization": Config.MOBILE_OPTIMIZATION,
                "redis_cache": redis_client is not None
            }
        }
        
        return create_response(data=system_data)
        
    except Exception as e:
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return create_response(error=str(e), status_code=500)

@app.route('/api/scraping-status', methods=['GET'])
@limiter.limit("30 per minute")
def get_scraping_status():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çŠ¶æ³è©³ç´°API"""
    try:
        today = datetime.now().strftime("%Y%m%d")
        
        # ä»Šæ—¥ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚°å–å¾—
        conn = db_manager.get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT url, status, response_time, data_count, error_message, created_at
        FROM scraping_log
        WHERE scraping_date = ?
        ORDER BY created_at DESC
        LIMIT 20
        ''', (today,))
        
        logs = cursor.fetchall()
        
        # çµ±è¨ˆè¨ˆç®—
        cursor.execute('''
        SELECT 
            COUNT(*) as total,
            SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as success,
            AVG(response_time) as avg_time,
            SUM(data_count) as total_data
        FROM scraping_log
        WHERE scraping_date = ?
        ''', (today,))
        
        stats = cursor.fetchone()
        conn.close()
        
        status_data = {
            "date": today,
            "limits": {
                "daily_count": scraping_count_today,
                "daily_limit": Config.MAX_SCRAPING_PER_DAY,
                "remaining": max(0, Config.MAX_SCRAPING_PER_DAY - scraping_count_today),
                "cache_only_mode": Config.CACHE_ONLY_MODE
            },
            "statistics": {
                "total_attempts": stats[0] if stats[0] else 0,
                "successful": stats[1] if stats[1] else 0,
                "success_rate": (stats[1] / stats[0]) if stats[0] and stats[0] > 0 else 0,
                "avg_response_time": round(stats[2], 3) if stats[2] else 0,
                "total_data_retrieved": stats[3] if stats[3] else 0
            },
            "recent_logs": [
                {
                    "url": log[0],
                    "status": log[1],
                    "response_time": round(log[2], 3) if log[2] else 0,
                    "data_count": log[3],
                    "error": log[4],
                    "timestamp": log[5]
                } for log in logs
            ],
            "recommendations": []
        }
        
        # æ¨å¥¨äº‹é …
        if scraping_count_today >= Config.MAX_SCRAPING_PER_DAY * 0.8:
            status_data["recommendations"].append("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™")
        
        if Config.CACHE_ONLY_MODE:
            status_data["recommendations"].append("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ªãƒ³ãƒªãƒ¼ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™")
        
        return create_response(data=status_data)
        
    except Exception as e:
        logger.error(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çŠ¶æ³å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return create_response(error=str(e), status_code=500)

# ===== ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿API =====
@app.route('/api/emergency/cache-only', methods=['POST'])
@limiter.limit("5 per minute")
def toggle_cache_only_mode():
    """ç·Šæ€¥æ™‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ªãƒ³ãƒªãƒ¼ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿"""
    try:
        data = request.get_json()
        enable = data.get('enable', True)
        
        Config.CACHE_ONLY_MODE = enable
        
        message = "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ªãƒ³ãƒªãƒ¼ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹ã«ã—ã¾ã—ãŸ" if enable else "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ªãƒ³ãƒªãƒ¼ãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹ã«ã—ã¾ã—ãŸ"
        
        logger.warning(f"ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿: {message}")
        
        return create_response(
            data={
                "cache_only_mode": Config.CACHE_ONLY_MODE,
                "scraping_status": "åœæ­¢ä¸­" if enable else "æœ‰åŠ¹"
            },
            message=message
        )
        
    except Exception as e:
        logger.error(f"ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return create_response(error=str(e), status_code=500)

# ===== ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆäº’æ›æ€§ç¶­æŒï¼‰ =====
@app.route('/api/real-data-test', methods=['GET'])
@limiter.limit("20 per minute")
def real_data_test():
    """ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæ¡ç”Ÿ1Rãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œç‰ˆï¼‰"""
    return get_race_entries_api('01', 1)

@app.route('/api/races/today', methods=['GET'])
@limiter.limit("30 per minute")
def get_today_races():
    """ä»Šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    try:
        mobile_optimized = hasattr(g, 'is_mobile') and g.is_mobile
        today = datetime.now().strftime("%Y%m%d")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—
        schedule_data = data_collector.get_cached_schedule(today)
        
        races = []
        for race in schedule_data:
            race_data = {
                "race_id": f"{today}{race['venue_code']}{race['race_number']:02d}",
                "venue_code": race['venue_code'],
                "venue_name": race['venue_name'],
                "race_number": race['race_number'],
                "scheduled_time": race['scheduled_time'],
                "is_active": race['status'] == 'scheduled'
            }
            races.append(race_data)
        
        return create_response(data={
            "races": races,
            "date": today,
            "mobile_optimized": mobile_optimized,
            "data_source": "cache"
        })
        
    except Exception as e:
        logger.error(f"ä»Šæ—¥ã®ãƒ¬ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return create_response(error=str(e), status_code=500)

# ===== AIäºˆæƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ =====
@app.route('/api/prediction/<race_id>', methods=['GET', 'POST'])
@limiter.limit("20 per minute")
def get_race_prediction(race_id):
    try:
        if not AI_AVAILABLE:
            return create_response(data=get_mock_prediction(race_id))
            
        prediction = ai_model.get_race_prediction(race_id)
        return create_response(data=prediction)
        
    except Exception as e:
        logger.error(f"AIäºˆæƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return create_response(data=get_mock_prediction(race_id))

def get_mock_prediction(race_id):
    """æ”¹è‰¯ç‰ˆãƒ¢ãƒƒã‚¯äºˆæƒ³ãƒ‡ãƒ¼ã‚¿"""
    return {
        "race_id": race_id,
        "predictions": [
            {"racer_id": 1, "boat_number": 1, "predicted_rank": 1, "rank_probabilities": [0.35, 0.25, 0.20, 0.12, 0.05, 0.03], "expected_value": 1.2, "confidence": 0.85},
            {"racer_id": 2, "boat_number": 2, "predicted_rank": 3, "rank_probabilities": [0.15, 0.20, 0.30, 0.20, 0.10, 0.05], "expected_value": 2.8, "confidence": 0.72},
            {"racer_id": 3, "boat_number": 3, "predicted_rank": 2, "rank_probabilities": [0.25, 0.35, 0.25, 0.10, 0.03, 0.02], "expected_value": 2.3, "confidence": 0.78},
            {"racer_id": 4, "boat_number": 4, "predicted_rank": 5, "rank_probabilities": [0.08, 0.10, 0.15, 0.25, 0.30, 0.12], "expected_value": 4.8, "confidence": 0.63},
            {"racer_id": 5, "boat_number": 5, "predicted_rank": 4, "rank_probabilities": [0.10, 0.08, 0.08, 0.25, 0.35, 0.14], "expected_value": 4.2, "confidence": 0.68},
            {"racer_id": 6, "boat_number": 6, "predicted_rank": 6, "rank_probabilities": [0.07, 0.02, 0.02, 0.08, 0.17, 0.64], "expected_value": 5.4, "confidence": 0.71}
        ],
        "forecast": {
            "win": {"boat_number": 1, "confidence": 0.85},
            "quinella": {"combination": [1, 3], "confidence": 0.78},
            "exacta": {"combination": [1, 3], "confidence": 0.72},
            "trio": {"combination": [1, 3, 2], "confidence": 0.68}
        },
        "risk_analysis": {
            "stability_score": 78,
            "upset_probability": 22,
            "reliability": "é«˜"
        }
    }

# ===== ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ– =====
def initialize_app():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–"""
    try:
        logger.info("=== æ­£å¼ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç‰ˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–é–‹å§‹ ===")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        db_manager.initialize_all_tables()
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
        
        # ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹
        schedule_manager.start_scheduled_tasks()
        logger.info("âœ… ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹å®Œäº†")
        
        logger.info("=== ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Œäº† ===")
        
    except Exception as e:
        logger.error(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise e

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        initialize_app()
        
        # AIåˆæœŸåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if AI_AVAILABLE:
            logger.info("AIå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†")
        
        # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
        port = int(os.environ.get('PORT', 5000))
        logger.info(f"ğŸš€ WAVE PREDICTOR æ­£å¼ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç‰ˆ Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹: ãƒãƒ¼ãƒˆ {port}")
        
        app.run(
            debug=app.config['DEBUG'], 
            host='0.0.0.0', 
            port=port,
            threaded=True
        )
        
    except Exception as e:
        logger.error(f"Application startup failed: {e}")
        raise e

# ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«è‡ªå‹•å®Ÿè¡Œ
try:
    initialize_app()
except Exception as e:
    logger.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å¤±æ•—: {str(e)}")

if __name__ == '__main__':
    main()
